import nbformat as nbf

# Create a new notebook
nb = nbf.v4.new_notebook()

# Define the cells in the notebook
cells = []

# Cell 1: Imports
imports = """
# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
"""

cells.append(nbf.v4.new_code_cell(imports))

# Cell 2: Data Loading
data_loading = """
# Load the Excel file and inspect sheet names
file_path = '/mnt/data/My_Excel_Project_Dataset.xlsx'
excel_data = pd.ExcelFile(file_path)

# Check available sheets
sheet_names = excel_data.sheet_names
print("Available sheets:", sheet_names)

# Load relevant sheets into DataFrames
bike_buyers_df = excel_data.parse('bike_buyers')
working_sheet_df = excel_data.parse('Working Sheet')
pivot_table_df = excel_data.parse('Pivot Table')

# Display the first few rows of each loaded sheet
bike_buyers_df.head(), working_sheet_df.head(), pivot_table_df.head()
"""

cells.append(nbf.v4.new_code_cell(data_loading))

# Cell 3: Basic Summary and Info
summary_info = """
# Display basic info and summary statistics for each dataset
print("Bike Buyers Data Info:")
bike_buyers_df.info()
print("\\nWorking Sheet Data Info:")
working_sheet_df.info()
print("\\nPivot Table Data Info:")
pivot_table_df.info()

# Summary statistics
print("Summary Statistics - Bike Buyers")
bike_buyers_df.describe(include='all')
"""

cells.append(nbf.v4.new_code_cell(summary_info))

# Cell 4: Data Cleaning and Handling Missing Values
data_cleaning = """
# Checking for missing values in the bike buyers sheet
print("Missing values in bike buyers dataset:")
print(bike_buyers_df.isnull().sum())

# Handling missing values (if any)
# Example: Fill numerical columns with the median, categorical with the mode
for column in bike_buyers_df.columns:
    if bike_buyers_df[column].dtype == 'object':
        bike_buyers_df[column].fillna(bike_buyers_df[column].mode()[0], inplace=True)
    else:
        bike_buyers_df[column].fillna(bike_buyers_df[column].median(), inplace=True)

print("Missing values handled.")
"""

cells.append(nbf.v4.new_code_cell(data_cleaning))

# Cell 5: EDA - Univariate Analysis
eda_univariate = """
# Univariate analysis: Plotting distributions for numerical columns
plt.figure(figsize=(14, 10))
plt.subplot(2, 2, 1)
sns.histplot(bike_buyers_df['Income'], kde=True)
plt.title('Income Distribution')

plt.subplot(2, 2, 2)
sns.histplot(bike_buyers_df['Age'], kde=True)
plt.title('Age Distribution')

plt.subplot(2, 2, 3)
sns.countplot(data=bike_buyers_df, x='Marital Status')
plt.title('Marital Status Counts')

plt.subplot(2, 2, 4)
sns.countplot(data=bike_buyers_df, x='Purchased Bike')
plt.title('Bike Purchase Counts')

plt.tight_layout()
plt.show()
"""

cells.append(nbf.v4.new_code_cell(eda_univariate))

# Cell 6: EDA - Bivariate Analysis
eda_bivariate = """
# Bivariate analysis: Analyzing relationships between features and target variable (Purchased Bike)

plt.figure(figsize=(14, 10))
plt.subplot(2, 2, 1)
sns.boxplot(data=bike_buyers_df, x='Purchased Bike', y='Income')
plt.title('Income by Bike Purchase')

plt.subplot(2, 2, 2)
sns.boxplot(data=bike_buyers_df, x='Purchased Bike', y='Age')
plt.title('Age by Bike Purchase')

plt.subplot(2, 2, 3)
sns.countplot(data=bike_buyers_df, x='Commute Distance', hue='Purchased Bike')
plt.title('Commute Distance and Bike Purchase')

plt.subplot(2, 2, 4)
sns.countplot(data=bike_buyers_df, x='Marital Status', hue='Purchased Bike')
plt.title('Marital Status and Bike Purchase')

plt.tight_layout()
plt.show()
"""

cells.append(nbf.v4.new_code_cell(eda_bivariate))

# Cell 7: Correlation Analysis
correlation_analysis = """
# Correlation analysis to find relationships among numerical features
plt.figure(figsize=(10, 6))
sns.heatmap(bike_buyers_df.corr(), annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()
"""

cells.append(nbf.v4.new_code_cell(correlation_analysis))

# Cell 8: Predictive Modeling - Logistic Regression
predictive_modeling = """
# Prepare data for predictive modeling
X = bike_buyers_df[['Income', 'Age', 'Cars']]  # Example feature selection
y = bike_buyers_df['Purchased Bike'].apply(lambda x: 1 if x == 'Yes' else 0)

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train a Logistic Regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Make predictions and evaluate the model
y_pred = model.predict(X_test)
print("Classification Report:")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("Accuracy Score:", accuracy_score(y_test, y_pred))
"""

cells.append(nbf.v4.new_code_cell(predictive_modeling))

# Cell 9: Conclusion
conclusion = """
# Conclusion and Summary
# Summarize key insights from the analysis and model performance.
# Mention potential recommendations based on the findings.
"""

cells.append(nbf.v4.new_markdown_cell(conclusion))

# Add all cells to the notebook
nb['cells'] = cells

# Save the notebook to a file
output_path = '/mnt/data/Advanced_Data_Analysis_Project.ipynb'
with open(output_path, 'w') as f:
    nbf.write(nb, f)

output_path
